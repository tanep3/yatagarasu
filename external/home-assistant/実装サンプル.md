### 自前実装に必要なHA API実装例

#### 1. 動体検知を自前コードに届ける方法（最優先）
- **WebSocketでsubscribe_events**（レイテンシ最小、推奨）
  - エンドポイント: `ws://<HA_IP>:8123/api/websocket`
  - 認証後、以下メッセージ送信
    ```json
    {
      "id": 1,
      "type": "subscribe_events",
      "event_type": "state_changed"
    }
    ```
  - 返ってくるイベント例（動体検知時）
    ```json
    {
      "id": 1,
      "type": "event",
      "event": {
        "event_type": "state_changed",
        "data": {
          "entity_id": "binary_sensor.tapo_tc70_motion",
          "old_state": { "state": "off" },
          "new_state": { "state": "on", "last_changed": "2026-02-23T01:43:00+09:00" }
        }
      }
    }
    ```
  - → これを受けたら、自分のPythonで即ffmpeg起動（RTSP音声抜き出し）＋スナップショットAPIコール

- **Webhook代替**（シンプルだが1往復遅延）
  - Automationで「binary_sensor.tapo_tc70_motion がonになったら」→ shell_command or http.request で自分のサーバーのWebhookを叩く
  - HA側のAutomation YAML例（ha_config/automations.yamlに追加）
    ```yaml
    - id: tapo_motion_webhook
      alias: Tapo Motion to Webhook
      trigger:
        - platform: state
          entity_id: binary_sensor.tapo_tc70_motion
          to: 'on'
      action:
        - service: http.request
          data:
            url: "http://localhost:9000/tapo_motion_trigger"  # 自分のPythonサーバー
            method: POST
            json:
              entity_id: "{{ trigger.entity_id }}"
              timestamp: "{{ now() }}"
    ```

#### 2. 写真（スナップショット）を取得するAPI
- **REST API**: `/api/camera_proxy/camera.tapo_tc70` で即時画像バイナリ取得
  - 例（自分のPythonから）
    ```python
    import requests
    headers = {"Authorization": "Bearer YOUR_LONG_LIVED_TOKEN"}
    r = requests.get("http://192.168.0.100:8123/api/camera_proxy/camera.tapo_tc70", headers=headers)
    with open("motion_snapshot.jpg", "wb") as f:
        f.write(r.content)
    ```
- **go2rtc経由のスナップショット**（遅延最小）
  - `http://<GO2RTC_IP>:1984/api/frame.jpeg?src=tapo_tc70`  
  → HAを通さず直接go2rtcから取れるので、動体検知イベント後即コール推奨

#### 3. 常時音声を取得（RTSPストリーム）
- go2rtcが配信しているRTSP URLを自前でffmpegに食わせるだけ
  - 例: `rtsp://192.168.0.100:8554/tapo_tc70`
  - ffmpegで音声のみ常時抜き出し（faster-whisperにパイプ）
    ```bash
    ffmpeg -i rtsp://192.168.0.100:8554/tapo_tc70 -f s16le -ac 1 -ar 16000 -vn - | python whisper_stream.py
    ```
  - 動体検知イベントでバッファ開始、30秒無音で処理→Claudeへ

#### 4. スピーカーから発声（双方向オーディオ）
- go2rtcの双方向オーディオはWebSocket or HTTP APIで制御
  - 発声したいとき: go2rtcの `/api/send` に音声データをPOST
  - zundaでWAV生成 → ffmpegでgo2rtcにプッシュ
    ```bash
    zunda "こんにちは" -o output.wav
    ffmpeg -i output.wav -f wav - | curl -X POST "http://192.168.0.100:1984/api/send?name=tapo_tc70" --data-binary @-
    ```
  - またはHAのservice `camera.turn_on` + `media_player.play_media` で間接制御も可能

### 今の認識確認
- HAは「Tapoの動体検知・ストリーム・スナップショット・オーディオを安定して露出するサーバー」としてだけ使う  
- メインのロジック（Whisper、Claude/GLM、zunda、記憶管理、オーケストレーション）はすべて自前実装  
- HAのAPI/WebSocketは「トリガー受信」「写真取得」「音声ストリームURLの安定供給」のためにだけ使う

